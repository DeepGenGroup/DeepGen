 === start mlir =====
module {
  func.func public @broadcast(%arg0: memref<32x16xf32, 1>) {
    affine.parallel (%arg1) = (0) to (16) {
      affine.parallel (%arg2) = (0) to (32) {
        %c16_i32 = arith.constant 16 : i32
        %c0_i32 = arith.constant 0 : i32
        %0 = affine.load %arg0[%arg1 + (%arg2 floordiv 16) * 16, %arg2 mod 16] : memref<32x16xf32, 1>
        %shuffleResult, %valid = gpu.shuffle  idx %0, %c0_i32, %c16_i32 : f32
        affine.store %shuffleResult, %arg0[%arg1 + (%arg2 floordiv 16) * 16, %arg2 mod 16] : memref<32x16xf32, 1>
      } {gpu.index = "threadIdx"}
    } {gpu.index = "blockIdx"}
    return
  }
}
 === after transforms =====
module attributes {kcg.externlibs = {library_0 = "/home/xiebaokang/projects/mlir/amendDeepGen/third_party/cuda/lib/libdevice.10.bc"}} {
  func.func public @broadcast(%arg0: memref<32x16xf32, 1>) attributes {func.block.dim = array<i32: 32>, func.grid.dim = array<i32: 16>} {
    %c0_i32 = arith.constant 0 : i32
    %c16_i32 = arith.constant 16 : i32
    %block_id_x = gpu.block_id  x
    %thread_id_x = gpu.thread_id  x
    %0 = affine.load %arg0[%block_id_x + (%thread_id_x floordiv 16) * 16, %thread_id_x mod 16] : memref<32x16xf32, 1>
    %shuffleResult, %valid = gpu.shuffle  idx %0, %c0_i32, %c16_i32 : f32
    affine.store %shuffleResult, %arg0[%block_id_x + (%thread_id_x floordiv 16) * 16, %thread_id_x mod 16] : memref<32x16xf32, 1>
    return
  }
}
 === after firstLowering =====
module attributes {kcg.externlibs = {library_0 = "/home/xiebaokang/projects/mlir/amendDeepGen/third_party/cuda/lib/libdevice.10.bc"}} {
  func.func public @broadcast(%arg0: memref<32x16xf32, 1>) attributes {func.block.dim = array<i32: 32>, func.grid.dim = array<i32: 16>} {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c16 = arith.constant 16 : index
    %c0_i32 = arith.constant 0 : i32
    %c16_i32 = arith.constant 16 : i32
    %block_id_x = gpu.block_id  x
    %thread_id_x = gpu.thread_id  x
    %0 = arith.cmpi slt, %thread_id_x, %c0 : index
    %1 = arith.subi %c-1, %thread_id_x : index
    %2 = arith.select %0, %1, %thread_id_x : index
    %3 = arith.divsi %2, %c16 : index
    %4 = arith.subi %c-1, %3 : index
    %5 = arith.select %0, %4, %3 : index
    %6 = arith.muli %5, %c16 overflow<nsw> : index
    %7 = arith.addi %block_id_x, %6 : index
    %8 = arith.remsi %thread_id_x, %c16 : index
    %9 = arith.cmpi slt, %8, %c0 : index
    %10 = arith.addi %8, %c16 : index
    %11 = arith.select %9, %10, %8 : index
    %12 = memref.load %arg0[%7, %11] : memref<32x16xf32, 1>
    %shuffleResult, %valid = gpu.shuffle  idx %12, %c0_i32, %c16_i32 : f32
    memref.store %shuffleResult, %arg0[%7, %11] : memref<32x16xf32, 1>
    return
  }
}
 === after secondLowering =====
module attributes {kcg.externlibs = {library_0 = "/home/xiebaokang/projects/mlir/amendDeepGen/third_party/cuda/lib/libdevice.10.bc"}} {
  llvm.func @broadcast(%arg0: !llvm.ptr<1>) attributes {func.block.dim = array<i32: 32>, func.grid.dim = array<i32: 16>, nvvm.kernel = true} {
    %0 = llvm.mlir.constant(4096 : i32) : i32
    %1 = llvm.mlir.constant(31 : i32) : i32
    %2 = llvm.mlir.constant(-1 : i32) : i32
    %3 = llvm.mlir.constant(0 : i32) : i32
    %4 = llvm.mlir.constant(-1 : index) : i32
    %5 = llvm.mlir.constant(16 : index) : i32
    %6 = llvm.mlir.constant(0 : index) : i32
    %7 = nvvm.read.ptx.sreg.ctaid.x : i32
    %8 = nvvm.read.ptx.sreg.tid.x : i32
    %9 = llvm.icmp "slt" %8, %6 : i32
    %10 = llvm.sub %4, %8 : i32
    %11 = llvm.select %9, %10, %8 : i1, i32
    %12 = llvm.sdiv %11, %5 : i32
    %13 = llvm.sub %4, %12 : i32
    %14 = llvm.select %9, %13, %12 : i1, i32
    %15 = llvm.mul %14, %5 overflow<nsw> : i32
    %16 = llvm.add %7, %15 : i32
    %17 = llvm.srem %8, %5 : i32
    %18 = llvm.icmp "slt" %17, %6 : i32
    %19 = llvm.add %17, %5 : i32
    %20 = llvm.select %18, %19, %17 : i1, i32
    %21 = llvm.mul %16, %5 : i32
    %22 = llvm.add %21, %20 : i32
    %23 = llvm.getelementptr %arg0[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %24 = llvm.load %23 : !llvm.ptr<1> -> f32
    %25 = llvm.add %0, %1 : i32
    %26 = nvvm.shfl.sync  idx %2, %24, %3, %25 : f32 -> f32
    llvm.store %26, %23 : f32, !llvm.ptr<1>
    llvm.return
  }
}
bin path: /tmp/compile-ptx-src-bf769c.cubin
==== ptx code: 
//
// Generated by LLVM NVPTX Back-End
//

.version 8.0
.target sm_80
.address_size 64

	// .globl	broadcast

.visible .entry broadcast(
	.param .u64 .ptr .global .align 1 broadcast_param_0
)
{
	.reg .b32 	%r<15>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<4>;

	ld.param.u64 	%rd1, [broadcast_param_0];
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	shr.s32 	%r3, %r2, 31;
	xor.b32  	%r4, %r3, %r2;
	shr.s32 	%r5, %r4, 31;
	shr.u32 	%r6, %r5, 28;
	add.s32 	%r7, %r4, %r6;
	shr.u32 	%r8, %r7, 4;
	xor.b32  	%r9, %r8, %r3;
	and.b32  	%r10, %r2, 15;
	shl.b32 	%r11, %r9, 8;
	shl.b32 	%r12, %r1, 4;
	add.s32 	%r13, %r11, %r12;
	or.b32  	%r14, %r13, %r10;
	mul.wide.s32 	%rd2, %r14, 4;
	add.s64 	%rd3, %rd1, %rd2;
	ld.global.f32 	%f1, [%rd3];
	shfl.sync.idx.b32	%f2, %f1, 0, 4127, -1;
	st.global.f32 	[%rd3], %f2;
	ret;

}

