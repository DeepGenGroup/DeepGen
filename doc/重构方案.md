
输入：
```python
class SomeModel(torch.Model) :
    def forward() :
        # ...
        C = torch.matmul(A,B)
        D = torch.relu(C)
        F = torch.matmul(D,E)
        # ...
        Z = torch.matmul(X,Y)
        # ...
```

after torchMLIR conversion :
```mlir
module{
    func.func @forward() {
        //...
        C = torch.aten.mm(A,B)
        D = torch.aten.relu(C)
        F = torch.aten.mm(D,E)
        //...
        Z = torch.aten.mm(X,Y)
    }
}

```
after lowering to mlir inner dialects :
```mlir
module{
    func.func @forward() {
        //...
        C = linalg.mm(A,B)
        D = linalg.relu(C)
        F = linalg.mm(D,E)
        //...
        Z = linalg.mm(X,Y)
    }
}

```

到这个阶段，kcgGraphAnalyzer 会对forward内的算子调用顺序进行分析. 生成朴素表达
```mlir
#! /bin/bash
inputMLIRFile=$1
# ~/rocm-llvm-install/bin/mlir-opt   -convert-elementwise-to-linalg \
#    -func-bufferize \
#    -linalg-bufferize \
#    -convert-linalg-to-affine-loops \
#    --affine-loop-tile  \
#    --affine-parallelize \
#    --convert-affine-for-to-gpu \
#    test.mlir 

~/rocm-llvm-install/bin/mlir-opt \
    -convert-elementwise-to-linalg \
   -func-bufferize \
   -linalg-bufferize \
    --arith-bufferize \
    -convert-linalg-to-parallel-loops \
    --convert-arith-to-amdgpu \
   -scf-parallel-loop-tiling \
    -convert-parallel-loops-to-gpu \
    --convert-scf-to-cf \
    --convert-cf-to-llvm \
    --convert-func-to-llvm \
    --convert-amdgpu-to-rocdl \
   ${inputMLIRFile} 

```

Runtime问题：
1.torch性能基本稳定，但是个别点偏离严重。如何确保在该情况下的数据置信度？（卡的性能偶尔下降）
——首次测定torch性能，作为Base。每测试500case，测试一下torch的性能和Base的比较。如果跳变超过分段阈值则暂停perf一段时间（或者换卡执行），之后再测试torch，直到冷却ok
——划定：4%以内认为合理。超出则暂停60s，（同时暂停kernel编译？）
2.每次perf进程重启后，torch基准会变动。需要存到文件保证一致性
——将torch的Base存进文件里
3.结果里直接显示case 耗时